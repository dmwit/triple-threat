\documentclass{article}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amsthm}
\usepackage{stmaryrd}
\newcommand{\lens}{\leftrightarrow}
\newcommand{\slens}{\lens_s}
\newcommand{\R}{\mathbb R}
\newtheorem{theorem}{Theorem}
\newtheorem{lemma}{Lemma}
\newtheorem{definition}{Definition}
\begin{document}
The goal is to take the theme ``bidirectional spreadsheet'' and run with it.
In particular we'd like to design something that would be helpful to
business people---who are familiar with normal unidirectional
spreadsheets---when they realize that a particular computation hasn't come
out the way they wanted it to, and are trying to figure out a way to guide
their business so that it comes out that way in the future.

(TODO: give a running example, so the drawbacks outlined in later sections
don't come as a surprise)

\section{Literal Interpretation}
\label{sec:naive}
One basic design idea is to simply describe the connections between cells
(called ``formulas'' in traditional spreadsheets) via a lens rather than a
one-way function. We can do this whenever:

\begin{enumerate}
    \item We know how to turn a particular math operator into a lens, that
        is, there's a ``good'' interpretation of inverting the operation.
    \item The formulas refer to each other in simple enough ways that we
        can use the monoidal structure of the category of lenses without
        relying on traced or cartesian structure (since we don't have
        those).
\end{enumerate}

In fact, when these conditions are satisfied, the lens laws tell us that
there is a \emph{unique} update to the spreadsheet induced by the lenses'
get and put functions.

To be specific, the second condition above can be formalized in the
following way. We identify a set $C$ of cell names, a set $T$ of types, and
a finite partial map $f \in C \to T$ giving the type of data stored in each
cell. We say a lens has spreadsheet-type $c_1 \times \cdots \times c_n
\slens c$ when $c, c_1, \ldots, c_n$ are pairwise distinct and the lens has
lens type $f(c_1) \times \cdots \times f(c_n) \lens f(c)$. Given a
collection of lenses and corresponding spreadsheet types, we can create a
directed graph whose nodes are $C$ and where there is an edge $(c,c')$ for
each lens whose type has the form $c_1 \times \cdots \times c' \times \cdots
\times c_n \slens c$. We say a collection of lenses has \emph{simple
structure} when there is at most one \emph{undirected} path between any pair
of nodes.

This is a fairly restrictive structural restriction, but note that it does
allow two (possibly surprising) setups: first, a given cell can have
multiple formulas associated with it, provided that they depend on disjoint
cell sets; second, multiple formulas can depend on a single cell, provided
the cells they output to are depended on by disjoint cell sets.

Suppose we now change the value in cell $c$. Pseudocode to update the rest
of the spreadsheet looks like this:

\newcommand\assign{\mathop{:=}}
\newcommand\modified{\mathit{modified}}
\newcommand\domain{\mathit{domain}}
\newcommand\codomain{\mathit{codomain}}
\begin{tabular}{l}
$\modified\assign\{c\}$ \\
iterate to fixpoint: \\
\qquad $k \assign $(nondeterministically) any lens \\
\qquad $f \assign $(nondeterministically) get or put \\
\qquad reject the choice when we would overwrite old work, i.e. when: \\
\qquad\qquad $k.f.\domain \cap \modified = \emptyset$ and $k.f.\codomain \cap \modified \ne \emptyset$ \\
\qquad run $k.f$ \\
\qquad $\modified \assign \modified \cup k.f.\codomain$
\end{tabular}

One should immediately ask whether this definition is really good, that is,
whether it terminates and is convergent. Showing these things relies
critically on the simple structure property, which gives us the crucial fact
that each cell changes its value at most once (in exactly the iteration
where it is added to the $\modified$ set).

(TODO: write down this argument carefully)

\newcommand{\tax}{\mathit{tax}}
\newcommand{\base}{\mathit{base}}
\newcommand{\total}{\mathit{total}}
The approach outlined above is simple to describe and implement, and it
reuses a lot of domain knowledge we have built up about lenses, but its
restrictions are strong enough that even fairly reasonable-looking
spreadsheets are excluded. For example, consider a spreadsheet with just
three cells named ``base'', ``tax'', and ``total''. We could imagine writing
a lens between base and tax that preserves the formula
$\tax=0.08*\base$, and similarly a lens between base, tax, and total
that preserves the formula $\total=\base+\tax$. However, the structure
restriction above is not satisfied in this spreadsheet: there are two paths
in the dependency graph from total to base (one that goes through tax and
one that doesn't).

Additionally, it isn't clear how to handle multi-update (that is, setting
the values of several cells simultaneously) or constrained update (that is,
fixing the values of some cells during the update process). The next two
sections discuss ways to address these shortcomings.

\section{Linear Algebra}
\label{sec:global-analysis}
Consider again the simple three-cell spreadsheet with two equations:
\begin{align*}
    \tax &= 0.08*\base \\
    \total &= \base+\tax
\end{align*}
We might observe that the $\total$ equation could be rewritten in terms of
just $\base$:
\begin{align*}
    \tax   &= 0.08*\base \\
    \total &= 1.08*\base
\end{align*}
The lenses implementing these two equations \emph{do} have the simple
structure property. One may wonder in exactly which circumstances such a
refactoring can be done -- and whether it could be done automatically. In
the following, we suggest one circumstance in which we can do quite well in
that direction.

Suppose for the moment that each lens' get is an affine function, and that
the dependency graph is acyclic. (Being acyclic is a significant relaxation
from the simple structure property, but being affine functions is a
significant strengthening of the ``any lens will do'' attitude from the
previous approach.) Call a cell a ``root cell'' if it has no out edges --
that is, none of the affine formulas in the spreadsheet output to root
cells. A simple argument shows that, given a cell in the spreadsheet, we
can write a affine formula which maps the values of root cells to the value
of the given cell. The argument goes by induction on the length of the
longest path from a root cell to the given one, and proceeds as in the
example above by substituting in affine formulas for each non-root variable
at each step. In fact, we can go a step farther: we can write affine
transformations from root cells to any set of cells. If we manage to give a
characterization of when these affine transformations can be
bidirectionalized, then we will have given an account of how to handle the
multi-update problem and relax the simple structure requirement in the parts
of the spreadsheet where only affine formulae are used.

Thus, we can now frame our problem in another way: what is the right way to
bidirectionalize an affine transformation? Accordingly, we will now step
away from spreadsheets and frame our discussion in linear algebra terms.

\newcommand{\argmin}[1]{\underset{#1}{\operatorname{argmin}}}
\newcommand{\lget}{\mathit{get}}
\newcommand{\lput}{\mathit{put}}
\newcommand{\x}{\mathbf x}
\newcommand{\y}{\mathbf y}
A function $\lget \in \R^m \to \R^n$ is affine exactly when there is a matrix
$M$ of dimension $n \times m$ and vector $\mathbf b \in \R^n$ such that $\lget(\x) =
M\x +\mathbf b$.  Affine functions are surjective (and hence bidirectionalizable)
just when $M$ has rank $n$, so we assume this. When $m=n$, $f$ is a
bijection. The put function in this case is particularly boring, because it
ignores the original source:
\[\lput(\x,\y) = M^{-1}\y\]
The more interesting case is when $m>n$, and where each $\y$ is therefore
the image of a nontrivial subspace of $\R^m$. There are many heuristics one
may choose to identify a particular point in this subspace; we choose the
specification:
\[\lput(\x,\y) = \argmin{\x',\lget(\x')=\y}||\x' - \x||\]

\newcommand{\transpose}{^\top}
\begin{theorem}
    There exists an $m \times n$ matrix $N$ such that
    \[\lput(\x,\y) = \x + N(\y - \lget(\x))\]
    satisfies the specification above.
\end{theorem}
\begin{proof}
    The intuition is that we wish to move as little as possible in
    source-space to match the move in target-space. This can be achieved by
    minimizing how far we move in the null space of $M$, since (exactly)
    these motions result in no motion in target-space.

    Take a basis $\{\x_1,\ldots,\x_{m-n}\}$ for the null space of $M$. Then
    we will take:
    \begin{align*}
        B &= \left[\begin{array}{c}
                \x_1\transpose \\
                \vdots \\
                \x_{m-n}\transpose
            \end{array}\right] \\
        N &= \left[\begin{array}{c}
                M \\
                B
            \end{array}\right]^{-1}
            \left[\begin{array}{c}
                I_n \\
                \mathbf 0_{m-n,n}
            \end{array}\right] \\
    \end{align*}
    We must now argue three things: that the square matrix in the definition
    of $N$ is invertible; that $N$ produces a put function that roundtrips;
    and that the put function produced by $N$ produces minimal changes. The
    definition above was crafted so that (assuming for the moment that $N$
    exists) we have $MN = I$, which is used to show the roundtrip property,
    and $BN = \mathbf 0$, which is used to show minimality.

    invertible: (TODO)

    roundtrip:
        \begin{align*}
            \lget(\lput(\x,\y))
                &= M(\x+N(\y-M\x-\mathbf b))+\mathbf b & \mbox{definition of }\lget,\lput \\
                &= MN\y + M\x + \mathbf b - MN(M\x + \mathbf b) & \mbox{rearranging terms} \\
                &= \y & MN=I
        \end{align*}

    minimal: (TODO)
\end{proof}

Pending research:
\begin{itemize}
    \item How do we solve constrained update ``optimally''?
    \item Can we generalize these observations? (What operations did we
        really need above? Can we be polymorphic over a theory that offers
        these operations? Are there other known instantiations of that
        theory?)
    \item how do the Shostak algorithm and Groebner bases fit in?
\end{itemize}
\section{Multiway Lenses}
% TODO: list all the ways to fix partiality
\label{sec:multiway}
The discussion in Section~\ref{sec:global-analysis} puts us in a slightly
uncomfortable situation: previously, our model could handle each lens having
exactly one output cell, but our analysis gave us the ability to treat
collections of cells as the output of a lens -- and indeed, to have a single
semantic object which could define lenses between the input cells and many
possible collections of output cells. Additionally, not all possible
collections of cells could act as outputs; in case the defining formulae for
the output cells were not linearly independent, the assumptions of the
analysis in terms of linear functions aren't satisfied. In this section, we
develop a more sophisticated semantic model which can capture these
additional behaviors. % TODO: motivate hiding

We will fix a set $T$ of spreadsheet values -- say, numbers and strings.

\newcommand{\sto}{\mapsto}
\newcommand{\mlens}[1]{\mathcal M(#1)}
\newcommand{\mput}{\mathit{put}}
\newcommand{\danger}{\mathcal D}

\begin{definition}
    A \emph{spreadsheet type} $C$ is a set of names.
\end{definition}

\begin{definition}
    An \emph{instance} $f$ of spreadsheet type $C$ is a function $C \to T$.
\end{definition}

\begin{definition}
    Given a spreadsheet type $N$, a \emph{multiway lens} $\ell : \mlens N$
    is a quadruple $(N',\danger,\mput,K)$ where
    \begin{itemize}
        \item $N'$ is a spreadsheet type disjoint from $N$,
        \item $\danger : 2^{2^N}$ is a predicate on sets of names,
        \item $\mput : 2^N \to (N \cup N' \to T) \to (N \cup N' \to T)$ is
            an update function which takes a set of names and an instance of
            the spreadsheet type $N \cup N'$ and produces another instance,
            and
        \item $K$ is an invariant expressed as a predicate on instances of
            $N \cup N'$.
    \end{itemize}
\end{definition}

\begin{definition}
    A multiway lens $\ell$ is \emph{well-formed} when it satisfies the
    following laws:
    \begin{itemize}
        \item $\danger$ is upwards-closed
        \item $\mput(i,f) \in K$ whenever $i \notin \danger$
        \item $\mput(i,f) = f$ whenever $f \in K$
        \item $\left.\mput(i,f)\right|_i = \left.f\right|_i$
    \end{itemize}
\end{definition}

\newcommand{\mdomain}[1]{\mathit{dom}(#1)}
\begin{definition}
    The \emph{domain} of lens $\ell : \mlens N$, denoted $\mdomain\ell$, is
    $N$.
\end{definition}

\begin{definition}
    Lenses $k : \mlens N$ and $\ell : \mlens N$ are \emph{equivalent},
    written $k \equiv \ell$, when $k.\danger = \ell.\danger$ and there
    exists a relation $R$ between instances of $k.N'$ and $\ell.N'$ such
    that whenever
    \begin{itemize}
        \item $f$ is an instance of $N$,
        \item $g\mathrel Rh$,
        \item $i \subset \mdomain k$, and
        \item $i \notin k.\danger$
    \end{itemize}
    we therefore necessarily have $k.\mput(i,f \cup g)=f' \cup g'$ and
    $\ell.\mput(i,f \cup h)=f' \cup h'$ for some instance $f'$ of $N$ and
    functions $g'\mathrel Rh'$.
\end{definition}

Conjecture: $\equiv$ is an equivalence relation.

For an implementation, storing an upward-closed element of $2^{2^N}$ is a
bit impractical (because of its size). In the remainder of the paper, we
will operate on representations of such sets.

\newcommand{\upclose}[2]{\llbracket #1 \rrbracket_{#2}}
\begin{definition}
    The \emph{upward closure} $\upclose VN$ of $V$ in $N$ is:
    \[S \in \upclose VN \iff \exists v \in V. v \subset S \subset N\]
\end{definition}

\begin{lemma}
    Upward closures are upward closed.
\end{lemma}

When a set of names $N$ is understood, we will use the notation
$E_{11}\cdots E_{1n_1},\cdots,E_{m1}\cdots E_{mn_m}$ as shorthand for
\[\upclose{\{\{E_{11},\cdots,E_{1n_1}\},\cdots,\{E_{m1},\cdots,E_{mn_m}\}\}}N\]
e.g. $AB,AC$ stands for $\{\{A,B\},\{A,C\},\{A,B,C\}\}$. In our definitions
below, we will give $\danger$ in these compact representations (and our
combinators will produce a representation from their sublenses'
representations of $\danger$).

\newcommand{\id}{\mathit{id}}
\begin{definition}
    The identity lens $\id : \mlens{\{A,B\}}$ is defined as follows:
    \begin{align*}
        C &= \{\} \\
        \danger &= AB \\
        \mput(\{A\},f) &= f[B \mapsto f(A)] \\
        \mput(i,f) &= f[A \mapsto f(B)] \\
        K(f) &= f(A) = f(B)
    \end{align*}
\end{definition}

\newcommand{\cond}[1]{\left\{\begin{array}{ll}#1\end{array}\right.}

\newcommand{\focus}{\mathit{focus}}
We will want to run put functions $p$ on bigger instances of spreadsheets
than $p$ may be expecting. For the variables $p$ doesn't know about, we'll
keep the old instance's values.
\begin{definition}
    \begin{align*}
        \focus(p,S,i,f,x) &= \cond{
            p(i \cap S,f|_S,x) & x \in S \\
            f(x) & x \notin S
        }
    \end{align*}
\end{definition}

\begin{definition}
    Suppose $k : \mlens{N_k}$ and $\ell : \mlens{N_\ell}$ and $k.C \cap
    \ell.C = \emptyset$. Denote their shared domain by $S=N_k \cap N_\ell$
    and the total domains (including hidden variables) by $T_k=N_k \cup k.C$
    and $T_\ell=N_\ell \cup \ell.C$. We define $k\mid\ell : \mlens{N_k \cup
    N_\ell}$ as:
    \begin{align*}
        C &= k.C \cup \ell.C \\
        \danger &= k.\danger \cup \ell.\danger \cup
            \{(d_k \cup d_\ell) \setminus S
            \mid d_k \in k.\danger, d_\ell \in \ell.\danger\} \\
        \mput(i) &= \cond{
            \focus(\ell.\mput,T_\ell,i) \circ \focus(k.\mput,T_k,i)
                & \mbox{ when possible} \\
            \focus(k.\mput,T_k,i) \circ \focus(\ell.\mput,T_\ell,i)
                & \mbox{ otherwise}
            } \\
        K(f) &= k.K(f|_{T_k}) \land \ell.K(f|_{T_\ell})
    \end{align*}
\end{definition}

\begin{definition}
    Given $\ell : \mlens N$ and $V \in N$, we define $\nu V.\ell : \mlens{N
    \setminus \{V\}}$:
    \begin{align*}
        C &= \ell.C \cup \{V\} \\
        \danger &= \{d \mid d \in \ell.\danger \land V \notin d\} \\
        \mput &= \ell.\mput \\
        K &= \ell.K
    \end{align*}
\end{definition}

\begin{definition}
    Given $\ell : \mlens N$ and two names $V \in N$ and $W \notin N$, we can
    give the renaming $\ell[W/V]$:
    \begin{align*}
        C &= \ell.C \\
        \danger &= \{d[W/V] \mid d \in \ell.\danger\} \\
        \mput(i,f) &= \ell.\mput(i[V/W], f[V/W])[W/V] \\
        K(f) &= \ell.K(f[V/W])
    \end{align*}
\end{definition}

Constants in the program can be implemented with a lens like this one.

\newcommand{\const}{\mathit{const}}
\begin{definition}
    If $t : T$ then $\const(t) : \mlens{\{A\}}$ is defined as:
    \begin{align*}
        C &= \{\} \\
        \danger &= A \\
        \mput(i,f) &= \lambda v. t \\
        K(f) &= f(A) = t
    \end{align*}
\end{definition}

Conjecture: all these lenses and combinators are well-behaved.

Known false wish: $k \mid \ell \equiv \ell \mid k$ (possible fix:
nondeterminism)

Known false wish: $(k \mid \ell) \mid m \equiv k \mid (\ell \mid m)$
(possible fixes: track more detailed information about put method
interleavings, multiway composition, more restrictive danger zones)

Conjecture: when $V \notin \mdomain k$, we have $\nu V. (k \mid \ell) \equiv
k \mid \nu V. \ell$.

Conjecture: when $k : A \lens B$ and $\ell : B \lens C$, we recover the
symmetric lens' $k;\ell : A \lens C$ via our $\nu B.(k \mid \ell)$.

(TODO: perhaps define a few other base lenses like affine transformations,
division/other operators, stringy stuff?)

Pending research:
\begin{itemize}
    \item more syntax and a big example
    \item other ideas we can take from process calculi? (e.g. name hiding,
        two different kinds of composition, etc.)
    \item types
    \item how do multicategories fit in?
\end{itemize}
\end{document}
